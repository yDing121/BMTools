{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f925e6f",
   "metadata": {},
   "source": [
    "# Host Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb52bc17",
   "metadata": {},
   "source": [
    "Command for running tool server:\\\n",
    "`python host_local_tools.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed26b4e",
   "metadata": {},
   "source": [
    "# Single Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3557dfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bmtools.agent.singletool import load_single_tools, STQuestionAnswerer\n",
    "from my_utils.load_keys import load_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d632131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded openai API\n"
     ]
    }
   ],
   "source": [
    "load_key(\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cae8397b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m[INFO|(BMTools)singletool:79]2023-07-11 17:33:42,949 >> \u001b[0m Using ChatGPT\n",
      "\u001b[1;31m[INFO|(BMTools)singletool:25]2023-07-11 17:33:42,953 >> \u001b[0m Doc string URL: http://127.0.0.1:8079/tools/weather/openapi.json\n",
      "\u001b[1;31m[INFO|(BMTools)singletool:34]2023-07-11 17:33:42,954 >> \u001b[0m server_url http://127.0.0.1:8079/tools/weather\n",
      "\u001b[1;31m[INFO|(BMTools)apitool:146]2023-07-11 17:33:42,955 >> \u001b[0m API Name: get_weather_today\n",
      "\u001b[1;31m[INFO|(BMTools)apitool:147]2023-07-11 17:33:42,956 >> \u001b[0m API Description: Get today's the weather. Your input should be a json (args json schema): {{\"location\" : string, }} The Action to trigger this API should be get_weather_today and the input parameters should be a json dict string. Pay attention to the type of parameters.\n",
      "\u001b[1;31m[INFO|(BMTools)apitool:146]2023-07-11 17:33:42,957 >> \u001b[0m API Name: forecast_weather\n",
      "\u001b[1;31m[INFO|(BMTools)apitool:147]2023-07-11 17:33:42,958 >> \u001b[0m API Description: Forecast weather in the upcoming days.. Your input should be a json (args json schema): {{\"location\" : string, \"days\" : integer, }} The Action to trigger this API should be forecast_weather and the input parameters should be a json dict string. Pay attention to the type of parameters.\n",
      "\u001b[1;31m[INFO|(BMTools)singletool:93]2023-07-11 17:33:42,959 >> \u001b[0m Tool [weather] has the following apis: [RequestTool(name='get_weather_today', description='Get today\\'s the weather. Your input should be a json (args json schema): {{\"location\" : string, }} The Action to trigger this API should be get_weather_today and the input parameters should be a json dict string. Pay attention to the type of parameters.', args_schema=None, return_direct=False, verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x000001D15E393730>, func=<function RequestTool.__init__.<locals>.func at 0x000001D14CE678B0>, afunc=<function RequestTool.__init__.<locals>.afunc at 0x000001D1211E19D0>, coroutine=None, tool_logo_md='', max_output_len=4000), RequestTool(name='forecast_weather', description='Forecast weather in the upcoming days.. Your input should be a json (args json schema): {{\"location\" : string, \"days\" : integer, }} The Action to trigger this API should be forecast_weather and the input parameters should be a json dict string. Pay attention to the type of parameters.', args_schema=None, return_direct=False, verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x000001D15E393730>, func=<function RequestTool.__init__.<locals>.func at 0x000001D14CF0E550>, afunc=<function RequestTool.__init__.<locals>.afunc at 0x000001D1211E1790>, coroutine=None, tool_logo_md='', max_output_len=4000)]\n",
      "\u001b[1;31m[INFO|(BMTools)singletool:113]2023-07-11 17:33:42,960 >> \u001b[0m Full prompt template: Answer the following questions as best you can. General instructions are: Plugin for look up weather information. Specifically, you have access to the following APIs:\n",
      "\n",
      "get_weather_today: Get today's the weather. Your input should be a json (args json schema): {{\"location\" : string, }} The Action to trigger this API should be get_weather_today and the input parameters should be a json dict string. Pay attention to the type of parameters.\n",
      "forecast_weather: Forecast weather in the upcoming days.. Your input should be a json (args json schema): {{\"location\" : string, \"days\" : integer, }} The Action to trigger this API should be forecast_weather and the input parameters should be a json dict string. Pay attention to the type of parameters.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [get_weather_today, forecast_weather]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Remember: (1) Follow the format, i.e,\n",
      "Thought:\n",
      "Action:\n",
      "Action Input:\n",
      "Observation:\n",
      "Final Answer:\n",
      ". The action you generate must be exact one of the given API names instead of a sentence or any other redundant text. The action input is one json format dict without any redundant text or bracket descriptions . (2) Provide as much as useful information (such as useful values/file paths in your observation) in your Final Answer. Do not describe the process you achieve the goal, but only provide the detailed answer or response to the task goal. (3) Do not make up anything. DO NOT generate observation content by yourself. (4) Read the observation carefully, and pay attention to the messages even if an error occurs. (5) Once you have enough information, please immediately use \n",
      "Thought: I have got enough information\n",
      "Final Answer: \n",
      "\n",
      "Task: {input}\n",
      "{agent_scratchpad}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weather {'schema_version': 'v1', 'name_for_human': 'Weather Info', 'name_for_model': 'Weather', 'description_for_human': 'Look up weather information', 'description_for_model': 'Plugin for look up weather information', 'auth': {'type': 'none'}, 'api': {'type': 'openapi', 'url': 'http://127.0.0.1:8079/tools/weather/openapi.json', 'is_user_authenticated': False}, 'author_github': None, 'logo_url': 'https://cdn.weatherapi.com/v4/images/weatherapi_logo.png', 'contact_email': 'hello@contact.com', 'legal_info_url': 'hello@legal.com'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutorWithTranslation chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to get the weather information for San Francisco today.\n",
      "Action: get_weather_today\n",
      "Action Input: {\"location\": \"San Francisco\"}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\"Today's weather report for San Francisco is:\\noverall: Partly cloudy,\\nname: San Francisco,\\nregion: California,\\ncountry: United States of America,\\nlocaltime: 2023-07-11 2:33,\\ntemperature: 11.1(C), 52.0(F),\\npercipitation: 0.0(mm), 0.0(inch),\\npressure: 1015.0(milibar),\\nhumidity: 89,\\ncloud: 25,\\nbody temperature: 10.0(C), 50.0(F),\\nwind speed: 15.5(kph), 9.6(mph),\\nvisibility: 16.0(km), 9.0(miles),\\nUV index: 1.0,\\n\"\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Could not parse LLM output: `I now know the final answer.`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m stqa \u001b[38;5;241m=\u001b[39m  STQuestionAnswerer()\n\u001b[0;32m      7\u001b[0m agent \u001b[38;5;241m=\u001b[39m stqa\u001b[38;5;241m.\u001b[39mload_tools(tool_name, tool_config, prompt_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreact-with-tool-description\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43magent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwrite a weather report for SF today\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m\"\"\" \u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03mfrom bmtools.agent.singletool import load_single_tools, STQuestionAnswerer\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03magent(\"Where is Yaoming Born?\")\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ToolBench\\lib\\site-packages\\langchain\\chains\\base.py:116\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ToolBench\\lib\\site-packages\\langchain\\chains\\base.py:113\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    108\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m    109\u001b[0m     inputs,\n\u001b[0;32m    110\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    111\u001b[0m )\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ToolBench\\lib\\site-packages\\langchain\\agents\\agent.py:792\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m    791\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m--> 792\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintermediate_steps\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    795\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m    796\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(next_step_output, intermediate_steps)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ToolBench\\lib\\site-packages\\langchain\\agents\\agent.py:672\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps)\u001b[0m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Take a single step in the thought-action-observation loop.\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \n\u001b[0;32m    669\u001b[0m \u001b[38;5;124;03mOverride this to take control of how the agent makes and acts on choices.\u001b[39;00m\n\u001b[0;32m    670\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m--> 672\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mplan(intermediate_steps, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m    673\u001b[0m \u001b[38;5;66;03m# If the tool chosen is the finishing tool, then we end and return.\u001b[39;00m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, AgentFinish):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ToolBench\\lib\\site-packages\\langchain\\agents\\agent.py:385\u001b[0m, in \u001b[0;36mAgent.plan\u001b[1;34m(self, intermediate_steps, **kwargs)\u001b[0m\n\u001b[0;32m    383\u001b[0m full_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_full_inputs(intermediate_steps, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    384\u001b[0m full_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfull_inputs)\n\u001b[1;32m--> 385\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ToolBench\\lib\\site-packages\\langchain\\agents\\mrkl\\output_parser.py:24\u001b[0m, in \u001b[0;36mMRKLOutputParser.parse\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     22\u001b[0m match \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(regex, text, re\u001b[38;5;241m.\u001b[39mDOTALL)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m match:\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse LLM output: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m action \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     26\u001b[0m action_input \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mOutputParserException\u001b[0m: Could not parse LLM output: `I now know the final answer.`"
     ]
    }
   ],
   "source": [
    "# Langchain\n",
    "tool_name, tool_url = 'weather',  \"http://127.0.0.1:8079/tools/weather/\"\n",
    "tool_name, tool_config = load_single_tools(tool_name, tool_url)\n",
    "print(tool_name, tool_config)\n",
    "stqa =  STQuestionAnswerer()\n",
    "\n",
    "agent = stqa.load_tools(tool_name, tool_config, prompt_type=\"react-with-tool-description\")\n",
    "agent(\"write a weather report for SF today\")\n",
    "\n",
    "\"\"\" \n",
    "from bmtools.agent.singletool import load_single_tools, STQuestionAnswerer\n",
    "\n",
    "tool_name, tool_url = 'wikipedia',  \"http://127.0.0.1:8079/tools/wikipedia/\"\n",
    "tool_name, tool_config = load_single_tools(tool_name, tool_url)\n",
    "print(tool_name, tool_config)\n",
    "stqa =  STQuestionAnswerer()\n",
    "\n",
    "agent = stqa.load_tools(tool_name, tool_config, prompt_type=\"babyagi\")\n",
    "# agent = stqa.load_tools(tool_name, tool_config, prompt_type=\"react-with-tool-description\")# prompt_type=\"babyagi\")\n",
    "agent(\"Where is Yaoming Born?\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e322944",
   "metadata": {},
   "source": [
    "# Multi Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdff7a2b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will register chemical-prop\n",
      "will register douban-film\n",
      "will register wikidata\n",
      "will register stock\n",
      "will register weather\n",
      "will register weather2\n",
      "will register chineseweather\n",
      "will register wikipedia\n",
      "will register wolframalpha\n",
      "will register office-ppt\n",
      "will register bing_search\n",
      "will register bing_map\n",
      "will register baidu_map\n",
      "will register nllb-translation\n",
      "will register baidu-translation\n",
      "will register tutorial\n",
      "will register file_operation\n",
      "will register meta_analysis\n",
      "will register database\n",
      "will register db_diag\n",
      "will register code_interpreter\n",
      "will register hugging_tools\n",
      "will register arxiv\n",
      "will register zillow\n",
      "will register google_scholar\n",
      "will register google_places\n",
      "will register google_serper\n",
      "will register python\n",
      "will register sceneXplain\n",
      "will register shell\n",
      "will register image_generation\n",
      "will register airbnb\n",
      "will register job_search\n",
      "will register gradio_tools\n",
      "will register travel\n",
      "will register walmart\n",
      "will register faq\n"
     ]
    }
   ],
   "source": [
    "from bmtools.agent.tools_controller import load_valid_tools, MTQuestionAnswerer\n",
    "from my_utils.load_keys import load_key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89270033",
   "metadata": {},
   "source": [
    "## Load API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdc9b09b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded openai API\n"
     ]
    }
   ],
   "source": [
    "load_key(\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50e551f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_mappings = {\n",
    "    'weather': \"http://127.0.0.1:8079/tools/weather/\",\n",
    "    'wolframalpha': \"http://127.0.0.1:8079/tools/wolframalpha/\",\n",
    "}\n",
    "\n",
    "tools = load_valid_tools(tools_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1fe1849",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m[INFO|(BMTools)tools_controller:46]2023-07-11 17:17:11,482 >> \u001b[0m Using ChatGPT\n",
      "\u001b[1;31m[INFO|(BMTools)tools_controller:55]2023-07-11 17:17:11,483 >> \u001b[0m All tools: {'weather': {'schema_version': 'v1', 'name_for_human': 'Weather Info', 'name_for_model': 'Weather', 'description_for_human': 'Look up weather information', 'description_for_model': 'Plugin for look up weather information', 'auth': {'type': 'none'}, 'api': {'type': 'openapi', 'url': 'http://127.0.0.1:8079/tools/weather/openapi.json', 'is_user_authenticated': False}, 'author_github': None, 'logo_url': 'https://cdn.weatherapi.com/v4/images/weatherapi_logo.png', 'contact_email': 'hello@contact.com', 'legal_info_url': 'hello@legal.com'}, 'wolframalpha': {'schema_version': 'v1', 'name_for_human': 'Wolfram', 'name_for_model': 'Wolfram', 'description_for_human': 'Access computation, math, curated knowledge & real-time data through Wolfram|Alpha and Wolfram Language.', 'description_for_model': '\"Dynamic computation and curated data from WolframAlpha and Wolfram Cloud.\\nOnly use the getWolframAlphaResults endpoints; all other Wolfram endpoints are deprecated.\\nPrefer getWolframAlphaResults unless Wolfram Language code should be evaluated.\\nTry to include images returned by getWolframAlphaResults. Queries to getWolframAlphaResults must ALWAYS have this structure: {\"input\": query}.\\n\",\\n        ', 'auth': {'type': 'none'}, 'api': {'type': 'openapi', 'url': 'http://127.0.0.1:8079/tools/wolframalpha/openapi.json', 'is_user_authenticated': False}, 'author_github': None, 'logo_url': 'https://www.wolframcdn.com/images/icons/Wolfram.png', 'contact_email': 'hello@contact.com', 'legal_info_url': 'hello@legal.com'}}\n",
      "\u001b[1;31m[INFO|(BMTools)singletool:79]2023-07-11 17:17:11,484 >> \u001b[0m Using ChatGPT\n",
      "\u001b[1;31m[INFO|(BMTools)singletool:25]2023-07-11 17:17:11,490 >> \u001b[0m Doc string URL: http://127.0.0.1:8079/tools/weather/openapi.json\n",
      "\u001b[1;31m[INFO|(BMTools)singletool:34]2023-07-11 17:17:11,490 >> \u001b[0m server_url http://127.0.0.1:8079/tools/weather\n",
      "\u001b[1;31m[INFO|(BMTools)apitool:146]2023-07-11 17:17:11,490 >> \u001b[0m API Name: get_weather_today\n",
      "\u001b[1;31m[INFO|(BMTools)apitool:147]2023-07-11 17:17:11,490 >> \u001b[0m API Description: Get today's the weather. Your input should be a json (args json schema): {{\"location\" : string, }} The Action to trigger this API should be get_weather_today and the input parameters should be a json dict string. Pay attention to the type of parameters.\n",
      "\u001b[1;31m[INFO|(BMTools)apitool:146]2023-07-11 17:17:11,490 >> \u001b[0m API Name: forecast_weather\n",
      "\u001b[1;31m[INFO|(BMTools)apitool:147]2023-07-11 17:17:11,490 >> \u001b[0m API Description: Forecast weather in the upcoming days.. Your input should be a json (args json schema): {{\"location\" : string, \"days\" : integer, }} The Action to trigger this API should be forecast_weather and the input parameters should be a json dict string. Pay attention to the type of parameters.\n",
      "\u001b[1;31m[INFO|(BMTools)singletool:93]2023-07-11 17:17:11,490 >> \u001b[0m Tool [weather] has the following apis: [RequestTool(name='get_weather_today', description='Get today\\'s the weather. Your input should be a json (args json schema): {{\"location\" : string, }} The Action to trigger this API should be get_weather_today and the input parameters should be a json dict string. Pay attention to the type of parameters.', args_schema=None, return_direct=False, verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x000001D15E393730>, func=<function RequestTool.__init__.<locals>.func at 0x000001D14CE67940>, afunc=<function RequestTool.__init__.<locals>.afunc at 0x000001D14CF0E940>, coroutine=None, tool_logo_md='', max_output_len=4000), RequestTool(name='forecast_weather', description='Forecast weather in the upcoming days.. Your input should be a json (args json schema): {{\"location\" : string, \"days\" : integer, }} The Action to trigger this API should be forecast_weather and the input parameters should be a json dict string. Pay attention to the type of parameters.', args_schema=None, return_direct=False, verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x000001D15E393730>, func=<function RequestTool.__init__.<locals>.func at 0x000001D17FA8F280>, afunc=<function RequestTool.__init__.<locals>.afunc at 0x000001D12115B5E0>, coroutine=None, tool_logo_md='', max_output_len=4000)]\n",
      "\u001b[1;31m[INFO|(BMTools)singletool:113]2023-07-11 17:17:11,490 >> \u001b[0m Full prompt template: Answer the following questions as best you can. General instructions are: Plugin for look up weather information. Specifically, you have access to the following APIs:\n",
      "\n",
      "get_weather_today: Get today's the weather. Your input should be a json (args json schema): {{\"location\" : string, }} The Action to trigger this API should be get_weather_today and the input parameters should be a json dict string. Pay attention to the type of parameters.\n",
      "forecast_weather: Forecast weather in the upcoming days.. Your input should be a json (args json schema): {{\"location\" : string, \"days\" : integer, }} The Action to trigger this API should be forecast_weather and the input parameters should be a json dict string. Pay attention to the type of parameters.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [get_weather_today, forecast_weather]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Remember: (1) Follow the format, i.e,\n",
      "Thought:\n",
      "Action:\n",
      "Action Input:\n",
      "Observation:\n",
      "Final Answer:\n",
      ". The action you generate must be exact one of the given API names instead of a sentence or any other redundant text. The action input is one json format dict without any redundant text or bracket descriptions . (2) Provide as much as useful information (such as useful values/file paths in your observation) in your Final Answer. Do not describe the process you achieve the goal, but only provide the detailed answer or response to the task goal. (3) Do not make up anything. DO NOT generate observation content by yourself. (4) Read the observation carefully, and pay attention to the messages even if an error occurs. (5) Once you have enough information, please immediately use \n",
      "Thought: I have got enough information\n",
      "Final Answer: \n",
      "\n",
      "Task: {input}\n",
      "{agent_scratchpad}\n",
      "\u001b[1;31m[INFO|(BMTools)singletool:79]2023-07-11 17:17:11,490 >> \u001b[0m Using ChatGPT\n",
      "\u001b[1;31m[INFO|(BMTools)singletool:25]2023-07-11 17:17:11,504 >> \u001b[0m Doc string URL: http://127.0.0.1:8079/tools/wolframalpha/openapi.json\n",
      "\u001b[1;31m[INFO|(BMTools)singletool:34]2023-07-11 17:17:11,504 >> \u001b[0m server_url http://127.0.0.1:8079/tools/wolframalpha\n",
      "\u001b[1;31m[INFO|(BMTools)apitool:146]2023-07-11 17:17:11,504 >> \u001b[0m API Name: getWolframAlphaResults\n",
      "\u001b[1;31m[INFO|(BMTools)apitool:147]2023-07-11 17:17:11,504 >> \u001b[0m API Description: Get Wolfram|Alpha results using natural query. Queries to getWolframAlphaResults must ALWAYS have this structure: {{\"input\": query}}. And please directly read the output json.. Your input should be a json (args json schema): {{\"input\" : string, }} The Action to trigger this API should be getWolframAlphaResults and the input parameters should be a json dict string. Pay attention to the type of parameters.\n",
      "\u001b[1;31m[INFO|(BMTools)singletool:93]2023-07-11 17:17:11,504 >> \u001b[0m Tool [wolframalpha] has the following apis: [RequestTool(name='getWolframAlphaResults', description='Get Wolfram|Alpha results using natural query. Queries to getWolframAlphaResults must ALWAYS have this structure: {{\"input\": query}}. And please directly read the output json.. Your input should be a json (args json schema): {{\"input\" : string, }} The Action to trigger this API should be getWolframAlphaResults and the input parameters should be a json dict string. Pay attention to the type of parameters.', args_schema=None, return_direct=False, verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x000001D15E393730>, func=<function RequestTool.__init__.<locals>.func at 0x000001D12115B3A0>, afunc=<function RequestTool.__init__.<locals>.afunc at 0x000001D12115B1F0>, coroutine=None, tool_logo_md='', max_output_len=4000)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m[INFO|(BMTools)singletool:113]2023-07-11 17:17:11,504 >> \u001b[0m Full prompt template: Answer the following questions as best you can. General instructions are: \"Dynamic computation and curated data from WolframAlpha and Wolfram Cloud.\n",
      "Only use the getWolframAlphaResults endpoints; all other Wolfram endpoints are deprecated.\n",
      "Prefer getWolframAlphaResults unless Wolfram Language code should be evaluated.\n",
      "Try to include images returned by getWolframAlphaResults. Queries to getWolframAlphaResults must ALWAYS have this structure: {{\"input\": query}}.\n",
      "\",. Specifically, you have access to the following APIs:\n",
      "\n",
      "getWolframAlphaResults: Get Wolfram|Alpha results using natural query. Queries to getWolframAlphaResults must ALWAYS have this structure: {{\"input\": query}}. And please directly read the output json.. Your input should be a json (args json schema): {{\"input\" : string, }} The Action to trigger this API should be getWolframAlphaResults and the input parameters should be a json dict string. Pay attention to the type of parameters.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [getWolframAlphaResults]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Remember: (1) Follow the format, i.e,\n",
      "Thought:\n",
      "Action:\n",
      "Action Input:\n",
      "Observation:\n",
      "Final Answer:\n",
      ". The action you generate must be exact one of the given API names instead of a sentence or any other redundant text. The action input is one json format dict without any redundant text or bracket descriptions . (2) Provide as much as useful information (such as useful values/file paths in your observation) in your Final Answer. Do not describe the process you achieve the goal, but only provide the detailed answer or response to the task goal. (3) Do not make up anything. DO NOT generate observation content by yourself. (4) Read the observation carefully, and pay attention to the messages even if an error occurs. (5) Once you have enough information, please immediately use \n",
      "Thought: I have got enough information\n",
      "Final Answer: \n",
      "\n",
      "Task: {input}\n",
      "{agent_scratchpad}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"thoughts\": {\n",
      "        \"text\": \"I should use the Weather plugin to look up the weather information in Beijing.\",\n",
      "        \"reasoning\": \"The user asked for the weather in Beijing, and the Weather plugin is specifically designed for looking up weather information.\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"Weather\",\n",
      "        \"args\": {\n",
      "            \"location\": \"Beijing\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutorWithTranslation chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The user wants to know the weather information for today in Beijing.\n",
      "\n",
      "Action: get_weather_today\n",
      "\n",
      "Action Input: {\"location\": \"Beijing\"}\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\"Today's weather report for Beijing is:\\noverall: Sunny,\\nname: Beijing,\\nregion: Beijing,\\ncountry: China,\\nlocaltime: 2023-07-11 17:17,\\ntemperature: 34.0(C), 93.2(F),\\npercipitation: 0.1(mm), 0.0(inch),\\npressure: 1000.0(milibar),\\nhumidity: 50,\\ncloud: 0,\\nbody temperature: 35.2(C), 95.3(F),\\nwind speed: 20.9(kph), 13.0(mph),\\nvisibility: 10.0(km), 6.0(miles),\\nUV index: 8.0,\\n\"\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Could not parse LLM output: `I now know the final answer.`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m qa \u001b[38;5;241m=\u001b[39m MTQuestionAnswerer(openai_api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, all_tools\u001b[38;5;241m=\u001b[39mtools)\n\u001b[0;32m      3\u001b[0m agent \u001b[38;5;241m=\u001b[39m qa\u001b[38;5;241m.\u001b[39mbuild_runner()\n\u001b[1;32m----> 5\u001b[0m \u001b[43magent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhat is the weather in Beijing?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Coding\\BMTools\\bmtools\\agent\\autogptmulti\\agent.py:120\u001b[0m, in \u001b[0;36mAutoGPT.__call__\u001b[1;34m(self, goals)\u001b[0m\n\u001b[0;32m    118\u001b[0m     tmp_json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser message\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m goals[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    119\u001b[0m     json_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(tmp_json)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 120\u001b[0m     observation \u001b[38;5;241m=\u001b[39m \u001b[43mtool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    122\u001b[0m     observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in args: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ToolBench\\lib\\site-packages\\langchain\\tools\\base.py:107\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mon_tool_error(e, verbose\u001b[38;5;241m=\u001b[39mverbose_)\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mon_tool_end(\n\u001b[0;32m    109\u001b[0m     observation, verbose\u001b[38;5;241m=\u001b[39mverbose_, color\u001b[38;5;241m=\u001b[39mcolor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    110\u001b[0m )\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m observation\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ToolBench\\lib\\site-packages\\langchain\\tools\\base.py:104\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, **kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    103\u001b[0m     tool_args, tool_kwargs \u001b[38;5;241m=\u001b[39m _to_args_and_kwargs(tool_input)\n\u001b[1;32m--> 104\u001b[0m     observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(\u001b[38;5;241m*\u001b[39mtool_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_kwargs)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mon_tool_error(e, verbose\u001b[38;5;241m=\u001b[39mverbose_)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ToolBench\\lib\\site-packages\\langchain\\agents\\tools.py:31\u001b[0m, in \u001b[0;36mTool._run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m     30\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Use the tool.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ToolBench\\lib\\site-packages\\langchain\\chains\\base.py:116\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ToolBench\\lib\\site-packages\\langchain\\chains\\base.py:113\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    108\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m    109\u001b[0m     inputs,\n\u001b[0;32m    110\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    111\u001b[0m )\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ToolBench\\lib\\site-packages\\langchain\\agents\\agent.py:792\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m    791\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m--> 792\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintermediate_steps\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    795\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m    796\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(next_step_output, intermediate_steps)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ToolBench\\lib\\site-packages\\langchain\\agents\\agent.py:672\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps)\u001b[0m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Take a single step in the thought-action-observation loop.\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \n\u001b[0;32m    669\u001b[0m \u001b[38;5;124;03mOverride this to take control of how the agent makes and acts on choices.\u001b[39;00m\n\u001b[0;32m    670\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m--> 672\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mplan(intermediate_steps, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m    673\u001b[0m \u001b[38;5;66;03m# If the tool chosen is the finishing tool, then we end and return.\u001b[39;00m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, AgentFinish):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ToolBench\\lib\\site-packages\\langchain\\agents\\agent.py:385\u001b[0m, in \u001b[0;36mAgent.plan\u001b[1;34m(self, intermediate_steps, **kwargs)\u001b[0m\n\u001b[0;32m    383\u001b[0m full_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_full_inputs(intermediate_steps, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    384\u001b[0m full_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfull_inputs)\n\u001b[1;32m--> 385\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ToolBench\\lib\\site-packages\\langchain\\agents\\mrkl\\output_parser.py:24\u001b[0m, in \u001b[0;36mMRKLOutputParser.parse\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     22\u001b[0m match \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(regex, text, re\u001b[38;5;241m.\u001b[39mDOTALL)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m match:\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse LLM output: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m action \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     26\u001b[0m action_input \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mOutputParserException\u001b[0m: Could not parse LLM output: `I now know the final answer.`"
     ]
    }
   ],
   "source": [
    "qa = MTQuestionAnswerer(openai_api_key='', all_tools=tools)\n",
    "\n",
    "agent = qa.build_runner()\n",
    "\n",
    "agent(\"what is the weather in Beijing?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57024f6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ToolBench",
   "language": "python",
   "name": "toolbench"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
