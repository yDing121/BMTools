{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f925e6f",
   "metadata": {},
   "source": [
    "# Host Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb52bc17",
   "metadata": {},
   "source": [
    "Command for running tool server:\\\n",
    "`python host_local_tools.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b494b37f",
   "metadata": {},
   "source": [
    "# Custom Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a17937ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import yaml\n",
    "from typing import Any, Dict, List, Union, NamedTuple\n",
    "import sys\n",
    "import re\n",
    "\n",
    "from bmtools.agent.apitool import RequestTool\n",
    "from bmtools.agent.executor import Executor, AgentExecutorWithTranslation\n",
    "from bmtools import get_logger\n",
    "from bmtools.agent.BabyagiTools import BabyAGI\n",
    "from bmtools.agent.singletool import import_all_apis, load_single_tools\n",
    "from bmtools import get_logger\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import OpenAI, LLMChain, PromptTemplate, SerpAPIWrapper\n",
    "from langchain.agents import ZeroShotAgent, AgentExecutor, initialize_agent, Tool\n",
    "from langchain.agents.agent import AgentOutputParser\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "from langchain.agents.mrkl.prompt import FORMAT_INSTRUCTIONS\n",
    "\n",
    "sys.path.insert(0, 'D:/Coding/ToolBench/data-generation')\n",
    "from answer.utils import prepare_queries, NAME2URL, MyZeroShotAgent, MyAgentExecutor, MyMRKLOutputParser, LogParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c3f829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basically copy the codes in singletool.py\n",
    "class STQuestionAnswerer:\n",
    "    def __init__(self, stream_output=False, llm_model=None):\n",
    "        self.llm = llm_model\n",
    "        self.stream_output = stream_output\n",
    "\n",
    "    def load_tools(self, name, meta_info, prompt_type=\"react-with-tool-description\", return_intermediate_steps=True):\n",
    "        self.all_tools_map = {}\n",
    "        self.all_tools_map[name] = import_all_apis(meta_info)\n",
    "\n",
    "        logger.info(\"Tool [{}] has the following apis: {}\".format(name, self.all_tools_map[name]))\n",
    "        tool_str = \"; \".join([t.name for t in self.all_tools_map[name]])\n",
    "\n",
    "        prefix = f\"\"\"Answer the following questions as best you can. Specifically, you have access to the following APIs:\"\"\"\n",
    "        suffix = \"\"\"Begin! Remember: (1) Follow the format, i.e,\\nThought:\\nAction:\\nAction Input:\\nObservation:\\nFinal Answer:\\n (2) Provide as much as useful information in your Final Answer. (3) Do not make up anything, and if your Observation has no link, DO NOT hallucihate one. (4) If you have enough information and want to stop the process, please use \\nThought: I have got enough information\\nFinal Answer: **your response in simplified chinese. \\n The Action: MUST be one of the following:\"\"\" + tool_str + \"\"\"\\nQuestion: {input}\\n Agent scratchpad (history actions):\\n {agent_scratchpad}\"\"\"\n",
    "\n",
    "        # Create prompt\n",
    "        prompt = ZeroShotAgent.create_prompt(\n",
    "            self.all_tools_map[name],\n",
    "            prefix=prefix,\n",
    "            suffix=suffix,\n",
    "#             prefix=CPREFIX,\n",
    "#             format_instructions=CFORMAT_INSTRUCTIONS,\n",
    "#             suffix=CSUFFIX,\n",
    "            input_variables=[\"input\", \"agent_scratchpad\"]\n",
    "        )\n",
    "        \n",
    "        print(prompt)\n",
    "\n",
    "        llm_chain = LLMChain(\n",
    "            llm=self.llm,\n",
    "            prompt=prompt\n",
    "        )\n",
    "        logger.info(\"Full prompt template: {}\".format(prompt.template))\n",
    "        tool_names = [tool.name for tool in self.all_tools_map[name] ]\n",
    "        agent = MyZeroShotAgent(llm_chain=llm_chain, allowed_tools=tool_names)\n",
    "        agent.output_parser = MyMRKLOutputParser()\n",
    "        if self.stream_output:\n",
    "            agent_executor = Executor.from_agent_and_tools(agent=agent, tools=self.all_tools_map[name] , verbose=True, return_intermediate_steps=return_intermediate_steps)\n",
    "        else:\n",
    "            agent_executor = MyAgentExecutor.from_agent_and_tools(agent=agent, tools=self.all_tools_map[name], verbose=True, return_intermediate_steps=return_intermediate_steps)\n",
    "        \n",
    "        agent_executor.early_stopping_method = \"generate\"\n",
    "        # print(type(prompt.template))\n",
    "        print(prompt.template)\n",
    "        return agent_executor, prompt.template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baa4c2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyZeroShotAgent(ZeroShotAgent):\n",
    "#     @property   \n",
    "#     def return_values(self) -> List[str]:\n",
    "#         \"\"\"Return values of the agent.\"\"\"\n",
    "#         return [\"output\", \"log\"]\n",
    "\n",
    "#     @property\n",
    "#     def llm_prefix(self) -> str:\n",
    "#         \"\"\"Prefix to append the llm call with.\"\"\"\n",
    "#         return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed26b4e",
   "metadata": {},
   "source": [
    "# Single Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3557dfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bmtools.agent.singletool import load_single_tools\n",
    "from my_utils.load_keys import load_key\n",
    "import langchain\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d632131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded openai API\n"
     ]
    }
   ],
   "source": [
    "load_key(\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cae8397b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m[INFO|(BMTools)singletool:25]2023-07-12 14:20:52,119 >> \u001b[0m Doc string URL: http://127.0.0.1:8079/tools/weather/openapi.json\n",
      "\u001b[1;31m[INFO|(BMTools)singletool:34]2023-07-12 14:20:52,119 >> \u001b[0m server_url http://127.0.0.1:8079/tools/weather\n",
      "\u001b[1;31m[INFO|(BMTools)apitool:146]2023-07-12 14:20:52,119 >> \u001b[0m API Name: get_weather_today\n",
      "\u001b[1;31m[INFO|(BMTools)apitool:147]2023-07-12 14:20:52,119 >> \u001b[0m API Description: Get today's the weather. Your input should be a json (args json schema): {{\"location\" : string, }} The Action to trigger this API should be get_weather_today and the input parameters should be a json dict string. Pay attention to the type of parameters.\n",
      "\u001b[1;31m[INFO|(BMTools)apitool:146]2023-07-12 14:20:52,119 >> \u001b[0m API Name: forecast_weather\n",
      "\u001b[1;31m[INFO|(BMTools)apitool:147]2023-07-12 14:20:52,119 >> \u001b[0m API Description: Forecast weather in the upcoming days.. Your input should be a json (args json schema): {{\"location\" : string, \"days\" : integer, }} The Action to trigger this API should be forecast_weather and the input parameters should be a json dict string. Pay attention to the type of parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weather {'schema_version': 'v1', 'name_for_human': 'Weather Info', 'name_for_model': 'Weather', 'description_for_human': 'Look up weather information', 'description_for_model': 'Plugin for look up weather information', 'auth': {'type': 'none'}, 'api': {'type': 'openapi', 'url': 'http://127.0.0.1:8079/tools/weather/openapi.json', 'is_user_authenticated': False}, 'author_github': None, 'logo_url': 'https://cdn.weatherapi.com/v4/images/weatherapi_logo.png', 'contact_email': 'hello@contact.com', 'legal_info_url': 'hello@legal.com'}\n",
      "input_variables=['input', 'agent_scratchpad'] output_parser=None partial_variables={} template='Answer the following questions as best you can. Specifically, you have access to the following APIs:\\n\\nget_weather_today: Get today\\'s the weather. Your input should be a json (args json schema): {{\"location\" : string, }} The Action to trigger this API should be get_weather_today and the input parameters should be a json dict string. Pay attention to the type of parameters.\\nforecast_weather: Forecast weather in the upcoming days.. Your input should be a json (args json schema): {{\"location\" : string, \"days\" : integer, }} The Action to trigger this API should be forecast_weather and the input parameters should be a json dict string. Pay attention to the type of parameters.\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [get_weather_today, forecast_weather]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Remember: (1) Follow the format, i.e,\\nThought:\\nAction:\\nAction Input:\\nObservation:\\nFinal Answer:\\n (2) Provide as much as useful information in your Final Answer. (3) Do not make up anything, and if your Observation has no link, DO NOT hallucihate one. (4) If you have enough information and want to stop the process, please use \\nThought: I have got enough information\\nFinal Answer: **your response in simplified chinese. \\n The Action: MUST be one of the following:get_weather_today; forecast_weather\\nQuestion: {input}\\n Agent scratchpad (history actions):\\n {agent_scratchpad}' template_format='f-string' validate_template=True\n",
      "Answer the following questions as best you can. Specifically, you have access to the following APIs:\n",
      "\n",
      "get_weather_today: Get today's the weather. Your input should be a json (args json schema): {{\"location\" : string, }} The Action to trigger this API should be get_weather_today and the input parameters should be a json dict string. Pay attention to the type of parameters.\n",
      "forecast_weather: Forecast weather in the upcoming days.. Your input should be a json (args json schema): {{\"location\" : string, \"days\" : integer, }} The Action to trigger this API should be forecast_weather and the input parameters should be a json dict string. Pay attention to the type of parameters.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [get_weather_today, forecast_weather]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Remember: (1) Follow the format, i.e,\n",
      "Thought:\n",
      "Action:\n",
      "Action Input:\n",
      "Observation:\n",
      "Final Answer:\n",
      " (2) Provide as much as useful information in your Final Answer. (3) Do not make up anything, and if your Observation has no link, DO NOT hallucihate one. (4) If you have enough information and want to stop the process, please use \n",
      "Thought: I have got enough information\n",
      "Final Answer: **your response in simplified chinese. \n",
      " The Action: MUST be one of the following:get_weather_today; forecast_weather\n",
      "Question: {input}\n",
      " Agent scratchpad (history actions):\n",
      " {agent_scratchpad}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MyAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: I need to get the weather for SF today\n",
      "Action: get_weather_today\n",
      "Action Input: {\"location\": \"SF\"}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\"Today's weather report for San Francisco is:\\noverall: Partly cloudy,\\nname: San Francisco,\\nregion: California,\\ncountry: United States of America,\\nlocaltime: 2023-07-11 23:20,\\ntemperature: 13.3(C), 55.9(F),\\npercipitation: 0.0(mm), 0.0(inch),\\npressure: 1016.0(milibar),\\nhumidity: 90,\\ncloud: 50,\\nbody temperature: 12.2(C), 53.9(F),\\nwind speed: 19.4(kph), 12.1(mph),\\nvisibility: 16.0(km), 9.0(miles),\\nUV index: 1.0,\\n\"\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
      "Final Answer: 今天旧金山的天气报告：总体情况为多云，名称为旧金山，地区为加利福尼亚州，国家为美国，当地时间为2023年7月11日23时20分，温度为13.3摄氏度（55.9华氏度），降水量为0.0毫米（0.0英寸），气压为1016.0米比弗，湿度为90，云量为50，体感温度为12.2摄氏度（53.9华氏度），风速为19.4公里/小时（12.1英里/小时），能见度为16.0公里（9.0英里），紫外线指数为1.0。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'write a weather report for SF today',\n",
       " 'output': '今天旧金山的天气报告：总体情况为多云，名称为旧金山，地区为加利福尼亚州，国家为美国，当地时间为2023年7月11日23时20分，温度为13.3摄氏度（55.9华氏度），降水量为0.0毫米（0.0英寸），气压为1016.0米比弗，湿度为90，云量为50，体感温度为12.2摄氏度（53.9华氏度），风速为19.4公里/小时（12.1英里/小时），能见度为16.0公里（9.0英里），紫外线指数为1.0。',\n",
       " 'intermediate_steps': [(AgentAction(tool='get_weather_today', tool_input='{\"location\": \"SF\"}', log='\\nThought: I need to get the weather for SF today\\nAction: get_weather_today\\nAction Input: {\"location\": \"SF\"}'),\n",
       "   '\"Today\\'s weather report for San Francisco is:\\\\noverall: Partly cloudy,\\\\nname: San Francisco,\\\\nregion: California,\\\\ncountry: United States of America,\\\\nlocaltime: 2023-07-11 23:20,\\\\ntemperature: 13.3(C), 55.9(F),\\\\npercipitation: 0.0(mm), 0.0(inch),\\\\npressure: 1016.0(milibar),\\\\nhumidity: 90,\\\\ncloud: 50,\\\\nbody temperature: 12.2(C), 53.9(F),\\\\nwind speed: 19.4(kph), 12.1(mph),\\\\nvisibility: 16.0(km), 9.0(miles),\\\\nUV index: 1.0,\\\\n\"')],\n",
       " 'log': 'Thought: I now know the final answer\\nFinal Answer: 今天旧金山的天气报告：总体情况为多云，名称为旧金山，地区为加利福尼亚州，国家为美国，当地时间为2023年7月11日23时20分，温度为13.3摄氏度（55.9华氏度），降水量为0.0毫米（0.0英寸），气压为1016.0米比弗，湿度为90，云量为50，体感温度为12.2摄氏度（53.9华氏度），风速为19.4公里/小时（12.1英里/小时），能见度为16.0公里（9.0英里），紫外线指数为1.0。'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Langchain\n",
    "logger = get_logger(__name__)\n",
    "tool_name, tool_url = 'weather',  \"http://127.0.0.1:8079/tools/weather/\"\n",
    "tool_name, tool_config = load_single_tools(tool_name, tool_url)\n",
    "print(tool_name, tool_config)\n",
    "stqa =  STQuestionAnswerer(llm_model=langchain.OpenAI(temperature=0, max_tokens=512))\n",
    "\n",
    "agent, prompt_template = stqa.load_tools(tool_name, tool_config, prompt_type=\"react-with-tool-description\")\n",
    "agent.return_intermediate_steps = True\n",
    "agent(\"write a weather report for SF today\")\n",
    "\n",
    "# \"\"\" \n",
    "# from bmtools.agent.singletool import load_single_tools, STQuestionAnswerer\n",
    "\n",
    "# tool_name, tool_url = 'wikipedia',  \"http://127.0.0.1:8079/tools/wikipedia/\"\n",
    "# tool_name, tool_config = load_single_tools(tool_name, tool_url)\n",
    "# print(tool_name, tool_config)\n",
    "# stqa =  STQuestionAnswerer()\n",
    "\n",
    "# agent = stqa.load_tools(tool_name, tool_config, prompt_type=\"babyagi\")\n",
    "# # agent = stqa.load_tools(tool_name, tool_config, prompt_type=\"react-with-tool-description\")# prompt_type=\"babyagi\")\n",
    "# agent(\"Where is Yaoming Born?\")\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e322944",
   "metadata": {},
   "source": [
    "# Multi Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdff7a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bmtools.agent.tools_controller import load_valid_tools, MTQuestionAnswerer\n",
    "from my_utils.load_keys import load_key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89270033",
   "metadata": {},
   "source": [
    "## Load API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdc9b09b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded openai API\n"
     ]
    }
   ],
   "source": [
    "load_key(\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50e551f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_mappings = {\n",
    "    'weather': \"http://127.0.0.1:8079/tools/weather/\",\n",
    "    'wolframalpha': \"http://127.0.0.1:8079/tools/wolframalpha/\",\n",
    "    'notool': \"http://127.0.0.1:8079/tools/notool/\"\n",
    "}\n",
    "\n",
    "tools = load_valid_tools(tools_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1fe1849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m[INFO|(BMTools)tools_controller:52]2023-07-12 14:24:40,026 >> \u001b[0m Using ChatGPT\n",
      "\u001b[1;31m[INFO|(BMTools)tools_controller:61]2023-07-12 14:24:40,028 >> \u001b[0m All tools: {'weather': {'schema_version': 'v1', 'name_for_human': 'Weather Info', 'name_for_model': 'Weather', 'description_for_human': 'Look up weather information', 'description_for_model': 'Plugin for look up weather information', 'auth': {'type': 'none'}, 'api': {'type': 'openapi', 'url': 'http://127.0.0.1:8079/tools/weather/openapi.json', 'is_user_authenticated': False}, 'author_github': None, 'logo_url': 'https://cdn.weatherapi.com/v4/images/weatherapi_logo.png', 'contact_email': 'hello@contact.com', 'legal_info_url': 'hello@legal.com'}, 'wolframalpha': {'schema_version': 'v1', 'name_for_human': 'Wolfram', 'name_for_model': 'Wolfram', 'description_for_human': 'Access computation, math, curated knowledge & real-time data through Wolfram|Alpha and Wolfram Language.', 'description_for_model': '\"Dynamic computation and curated data from WolframAlpha and Wolfram Cloud.\\nOnly use the getWolframAlphaResults endpoints; all other Wolfram endpoints are deprecated.\\nPrefer getWolframAlphaResults unless Wolfram Language code should be evaluated.\\nTry to include images returned by getWolframAlphaResults. Queries to getWolframAlphaResults must ALWAYS have this structure: {\"input\": query}.\\n\",\\n        ', 'auth': {'type': 'none'}, 'api': {'type': 'openapi', 'url': 'http://127.0.0.1:8079/tools/wolframalpha/openapi.json', 'is_user_authenticated': False}, 'author_github': None, 'logo_url': 'https://www.wolframcdn.com/images/icons/Wolfram.png', 'contact_email': 'hello@contact.com', 'legal_info_url': 'hello@legal.com'}, 'notool': {'schema_version': 'v1', 'name_for_human': 'Placeholder for no tool', 'name_for_model': 'Final Answer', 'description_for_human': 'Return a final answer', 'description_for_model': 'Tool for when you have a final answer', 'auth': {'type': 'none'}, 'api': {'type': 'openapi', 'url': 'http://127.0.0.1:8079/tools/notool/openapi.json', 'is_user_authenticated': False}, 'author_github': None, 'logo_url': '', 'contact_email': 'hello@contact.com', 'legal_info_url': 'hello@legal.com'}}\n",
      "\u001b[1;31m[INFO|(BMTools)singletool:80]2023-07-12 14:24:40,028 >> \u001b[0m Using ChatGPT\n",
      "\u001b[1;31m[INFO|(BMTools)singletool:25]2023-07-12 14:24:40,035 >> \u001b[0m Doc string URL: http://127.0.0.1:8079/tools/weather/openapi.json\n",
      "\u001b[1;31m[INFO|(BMTools)singletool:34]2023-07-12 14:24:40,035 >> \u001b[0m server_url http://127.0.0.1:8079/tools/weather\n",
      "\u001b[1;31m[INFO|(BMTools)apitool:146]2023-07-12 14:24:40,035 >> \u001b[0m API Name: get_weather_today\n",
      "\u001b[1;31m[INFO|(BMTools)apitool:147]2023-07-12 14:24:40,035 >> \u001b[0m API Description: Get today's the weather. Your input should be a json (args json schema): {{\"location\" : string, }} The Action to trigger this API should be get_weather_today and the input parameters should be a json dict string. Pay attention to the type of parameters.\n",
      "\u001b[1;31m[INFO|(BMTools)apitool:146]2023-07-12 14:24:40,035 >> \u001b[0m API Name: forecast_weather\n",
      "\u001b[1;31m[INFO|(BMTools)apitool:147]2023-07-12 14:24:40,035 >> \u001b[0m API Description: Forecast weather in the upcoming days.. Your input should be a json (args json schema): {{\"location\" : string, \"days\" : integer, }} The Action to trigger this API should be forecast_weather and the input parameters should be a json dict string. Pay attention to the type of parameters.\n",
      "\u001b[1;31m[INFO|(BMTools)singletool:94]2023-07-12 14:24:40,035 >> \u001b[0m Tool [weather] has the following apis: [RequestTool(name='get_weather_today', description='Get today\\'s the weather. Your input should be a json (args json schema): {{\"location\" : string, }} The Action to trigger this API should be get_weather_today and the input parameters should be a json dict string. Pay attention to the type of parameters.', args_schema=None, return_direct=False, verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x000001EA4BA93EE0>, func=<function RequestTool.__init__.<locals>.func at 0x000001EA7DF4E310>, afunc=<function RequestTool.__init__.<locals>.afunc at 0x000001EA7E55A1F0>, coroutine=None, tool_logo_md='', max_output_len=4000), RequestTool(name='forecast_weather', description='Forecast weather in the upcoming days.. Your input should be a json (args json schema): {{\"location\" : string, \"days\" : integer, }} The Action to trigger this API should be forecast_weather and the input parameters should be a json dict string. Pay attention to the type of parameters.', args_schema=None, return_direct=False, verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x000001EA4BA93EE0>, func=<function RequestTool.__init__.<locals>.func at 0x000001EA7D1A0700>, afunc=<function RequestTool.__init__.<locals>.afunc at 0x000001EA7E55A040>, coroutine=None, tool_logo_md='', max_output_len=4000)]\n",
      "\u001b[1;31m[INFO|(BMTools)singletool:114]2023-07-12 14:24:40,035 >> \u001b[0m Full prompt template: Answer the following questions as best you can. General instructions are: Plugin for look up weather information. Specifically, you have access to the following APIs:\n",
      "\n",
      "get_weather_today: Get today's the weather. Your input should be a json (args json schema): {{\"location\" : string, }} The Action to trigger this API should be get_weather_today and the input parameters should be a json dict string. Pay attention to the type of parameters.\n",
      "forecast_weather: Forecast weather in the upcoming days.. Your input should be a json (args json schema): {{\"location\" : string, \"days\" : integer, }} The Action to trigger this API should be forecast_weather and the input parameters should be a json dict string. Pay attention to the type of parameters.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [get_weather_today, forecast_weather]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Remember: (1) Follow the format, i.e,\n",
      "Thought:\n",
      "Action:\n",
      "Action Input:\n",
      "Observation:\n",
      "Final Answer:\n",
      ". The action you generate must be exact one of the given API names instead of a sentence or any other redundant text. The action input is one json format dict without any redundant text or bracket descriptions . (2) Provide as much as useful information (such as useful values/file paths in your observation) in your Final Answer. Do not describe the process you achieve the goal, but only provide the detailed answer or response to the task goal. (3) Do not make up anything. DO NOT generate observation content by yourself. (4) Read the observation carefully, and pay attention to the messages even if an error occurs. (5) Once you have enough information, please immediately use \n",
      "Thought: I have got enough information\n",
      "Final Answer: \n",
      "\n",
      "Task: {input}\n",
      "{agent_scratchpad}\n",
      "\u001b[1;31m[INFO|(BMTools)singletool:80]2023-07-12 14:24:40,035 >> \u001b[0m Using ChatGPT\n",
      "\u001b[1;31m[INFO|(BMTools)singletool:25]2023-07-12 14:24:40,035 >> \u001b[0m Doc string URL: http://127.0.0.1:8079/tools/wolframalpha/openapi.json\n",
      "\u001b[1;31m[INFO|(BMTools)singletool:34]2023-07-12 14:24:40,035 >> \u001b[0m server_url http://127.0.0.1:8079/tools/wolframalpha\n",
      "\u001b[1;31m[INFO|(BMTools)apitool:146]2023-07-12 14:24:40,035 >> \u001b[0m API Name: getWolframAlphaResults\n",
      "\u001b[1;31m[INFO|(BMTools)apitool:147]2023-07-12 14:24:40,035 >> \u001b[0m API Description: Get Wolfram|Alpha results using natural query. Queries to getWolframAlphaResults must ALWAYS have this structure: {{\"input\": query}}. And please directly read the output json.. Your input should be a json (args json schema): {{\"input\" : string, }} The Action to trigger this API should be getWolframAlphaResults and the input parameters should be a json dict string. Pay attention to the type of parameters.\n",
      "\u001b[1;31m[INFO|(BMTools)singletool:94]2023-07-12 14:24:40,035 >> \u001b[0m Tool [wolframalpha] has the following apis: [RequestTool(name='getWolframAlphaResults', description='Get Wolfram|Alpha results using natural query. Queries to getWolframAlphaResults must ALWAYS have this structure: {{\"input\": query}}. And please directly read the output json.. Your input should be a json (args json schema): {{\"input\" : string, }} The Action to trigger this API should be getWolframAlphaResults and the input parameters should be a json dict string. Pay attention to the type of parameters.', args_schema=None, return_direct=False, verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x000001EA4BA93EE0>, func=<function RequestTool.__init__.<locals>.func at 0x000001EA7DF0E8B0>, afunc=<function RequestTool.__init__.<locals>.afunc at 0x000001EA7E55A820>, coroutine=None, tool_logo_md='', max_output_len=4000)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m[INFO|(BMTools)singletool:114]2023-07-12 14:24:40,035 >> \u001b[0m Full prompt template: Answer the following questions as best you can. General instructions are: \"Dynamic computation and curated data from WolframAlpha and Wolfram Cloud.\n",
      "Only use the getWolframAlphaResults endpoints; all other Wolfram endpoints are deprecated.\n",
      "Prefer getWolframAlphaResults unless Wolfram Language code should be evaluated.\n",
      "Try to include images returned by getWolframAlphaResults. Queries to getWolframAlphaResults must ALWAYS have this structure: {{\"input\": query}}.\n",
      "\",. Specifically, you have access to the following APIs:\n",
      "\n",
      "getWolframAlphaResults: Get Wolfram|Alpha results using natural query. Queries to getWolframAlphaResults must ALWAYS have this structure: {{\"input\": query}}. And please directly read the output json.. Your input should be a json (args json schema): {{\"input\" : string, }} The Action to trigger this API should be getWolframAlphaResults and the input parameters should be a json dict string. Pay attention to the type of parameters.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [getWolframAlphaResults]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Remember: (1) Follow the format, i.e,\n",
      "Thought:\n",
      "Action:\n",
      "Action Input:\n",
      "Observation:\n",
      "Final Answer:\n",
      ". The action you generate must be exact one of the given API names instead of a sentence or any other redundant text. The action input is one json format dict without any redundant text or bracket descriptions . (2) Provide as much as useful information (such as useful values/file paths in your observation) in your Final Answer. Do not describe the process you achieve the goal, but only provide the detailed answer or response to the task goal. (3) Do not make up anything. DO NOT generate observation content by yourself. (4) Read the observation carefully, and pay attention to the messages even if an error occurs. (5) Once you have enough information, please immediately use \n",
      "Thought: I have got enough information\n",
      "Final Answer: \n",
      "\n",
      "Task: {input}\n",
      "{agent_scratchpad}\n",
      "\u001b[1;31m[INFO|(BMTools)singletool:80]2023-07-12 14:24:40,035 >> \u001b[0m Using ChatGPT\n",
      "\u001b[1;31m[INFO|(BMTools)singletool:25]2023-07-12 14:24:40,050 >> \u001b[0m Doc string URL: http://127.0.0.1:8079/tools/notool/openapi.json\n",
      "\u001b[1;31m[INFO|(BMTools)singletool:34]2023-07-12 14:24:40,050 >> \u001b[0m server_url http://127.0.0.1:8079/tools/notool\n",
      "\u001b[1;31m[INFO|(BMTools)apitool:146]2023-07-12 14:24:40,050 >> \u001b[0m API Name: final_answer\n",
      "\u001b[1;31m[INFO|(BMTools)apitool:147]2023-07-12 14:24:40,050 >> \u001b[0m API Description: .  The Action to trigger this API should be final_answer and the input parameters should be a json dict string. Pay attention to the type of parameters.\n",
      "\u001b[1;31m[INFO|(BMTools)singletool:94]2023-07-12 14:24:40,050 >> \u001b[0m Tool [notool] has the following apis: [RequestTool(name='final_answer', description='.  The Action to trigger this API should be final_answer and the input parameters should be a json dict string. Pay attention to the type of parameters.', args_schema=None, return_direct=False, verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x000001EA4BA93EE0>, func=<function RequestTool.__init__.<locals>.func at 0x000001EA7E55A3A0>, afunc=<function RequestTool.__init__.<locals>.afunc at 0x000001EA7E55A5E0>, coroutine=None, tool_logo_md='', max_output_len=4000)]\n",
      "\u001b[1;31m[INFO|(BMTools)singletool:114]2023-07-12 14:24:40,054 >> \u001b[0m Full prompt template: Answer the following questions as best you can. General instructions are: Tool for when you have a final answer. Specifically, you have access to the following APIs:\n",
      "\n",
      "final_answer: .  The Action to trigger this API should be final_answer and the input parameters should be a json dict string. Pay attention to the type of parameters.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [final_answer]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Remember: (1) Follow the format, i.e,\n",
      "Thought:\n",
      "Action:\n",
      "Action Input:\n",
      "Observation:\n",
      "Final Answer:\n",
      ". The action you generate must be exact one of the given API names instead of a sentence or any other redundant text. The action input is one json format dict without any redundant text or bracket descriptions . (2) Provide as much as useful information (such as useful values/file paths in your observation) in your Final Answer. Do not describe the process you achieve the goal, but only provide the detailed answer or response to the task goal. (3) Do not make up anything. DO NOT generate observation content by yourself. (4) Read the observation carefully, and pay attention to the messages even if an error occurs. (5) Once you have enough information, please immediately use \n",
      "Thought: I have got enough information\n",
      "Final Answer: \n",
      "\n",
      "Task: {input}\n",
      "{agent_scratchpad}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"thoughts\": {\n",
      "        \"text\": \"I should start by checking the weather.\",\n",
      "        \"reasoning\": \"Knowing the weather can help me plan my next actions.\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"Weather\",\n",
      "        \"args\": {\n",
      "            \"goal\": \"Check the current weather\"\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AgentFinish' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m qa \u001b[38;5;241m=\u001b[39m MTQuestionAnswerer(openai_api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, all_tools\u001b[38;5;241m=\u001b[39mtools)\n\u001b[0;32m      3\u001b[0m agent \u001b[38;5;241m=\u001b[39m qa\u001b[38;5;241m.\u001b[39mbuild_runner()\n\u001b[1;32m----> 5\u001b[0m \u001b[43magent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHow are you\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Coding\\BMTools\\bmtools\\agent\\autogptmulti\\agent.py:110\u001b[0m, in \u001b[0;36mAutoGPT.__call__\u001b[1;34m(self, goals)\u001b[0m\n\u001b[0;32m    107\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_parser\u001b[38;5;241m.\u001b[39mparse(assistant_reply)\n\u001b[0;32m    108\u001b[0m tools \u001b[38;5;241m=\u001b[39m {t\u001b[38;5;241m.\u001b[39mname: t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools}\n\u001b[1;32m--> 110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43maction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m \u001b[38;5;241m==\u001b[39m FINISH_NAME:\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m action\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m action\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m tools:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'AgentFinish' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "qa = MTQuestionAnswerer(openai_api_key='', all_tools=tools)\n",
    "\n",
    "agent = qa.build_runner()\n",
    "\n",
    "agent(\"How are you\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57024f6",
   "metadata": {},
   "source": [
    "# LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261d4b2a",
   "metadata": {},
   "source": [
    "## Load API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed4b6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_key(\"serpapi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded246c3",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c6d9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8387413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The language model we're going to use to control the agent.\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "\n",
    "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9649c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test it out!\n",
    "agent.run(\"Tell me about yourself\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe159d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ToolBench",
   "language": "python",
   "name": "toolbench"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
